{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "Xi3rTpJTaxxS"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import utils as nn_utils\n",
    "import os\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.animation import FuncAnimation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# torch.manual_seed(0)\n",
    "# np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "MKDooPkja29R"
   },
   "outputs": [],
   "source": [
    "def generate_line(n, sign = \"+\"):\n",
    "    t = torch.linspace(-3, 3, n)\n",
    "    x = t.view(-1, 1)\n",
    "    if sign == \"+\":\n",
    "        y = t.view(-1, 1)\n",
    "    else:\n",
    "        y = -t.view(-1, 1)\n",
    "    return torch.cat((x, y), dim=1).unsqueeze(0)\n",
    "\n",
    "\n",
    "def generate_line_small(n, sign = \"+\"):\n",
    "    t = torch.linspace(-1, 1, n)\n",
    "    x = t.view(-1, 1)\n",
    "    if sign == \"+\":\n",
    "        y = t.view(-1, 1)\n",
    "    else:\n",
    "        y = -t.view(-1, 1)\n",
    "    return torch.cat((x, y), dim=1).unsqueeze(0)\n",
    "\n",
    "def generate_parabola(n, sign = \"+\"):\n",
    "    t = torch.linspace(-10, 10, n)\n",
    "    x = (t).view(-1, 1)\n",
    "    if sign == \"+\":\n",
    "        y =((t**2).view(-1, 1) + 5)/5\n",
    "    else:\n",
    "        y = (-(t**2).view(-1, 1) - 5)/5\n",
    "    return torch.cat((x, y), dim=1).unsqueeze(0)\n",
    "\n",
    "def generate_circle(n, r = 1):\n",
    "    t = torch.linspace(0, 2 * torch.pi - 1e-3, n)\n",
    "    x = (r * torch.cos(t)).view(-1, 1)\n",
    "    y = (r * torch.sin(t)).view(-1, 1)\n",
    "    return torch.cat((x, y), dim=1).unsqueeze(0)\n",
    "\n",
    "\n",
    "def generate_sphere(n, a = 1, b = 1, c = 1):\n",
    "    t1 = torch.linspace(0, 2*torch.pi - 1e-3, n)\n",
    "    t2 = torch.linspace(0, torch.pi - 1e-3, n)\n",
    "    grid_t1, grid_t2 = torch.meshgrid((t1, t2), indexing='ij')\n",
    "    # t = torch.stack((grid_t1, grid_t2), dim=-1).reshape(-1, 2).to(device)\n",
    "    x = (a * torch.sin(grid_t1) * torch.cos(grid_t2)).view(-1, 1)\n",
    "    y = (b * torch.sin(grid_t1) *  torch.sin(grid_t2)).view(-1, 1)\n",
    "    z = (c * torch.cos(grid_t1)).view(-1, 1)\n",
    "    return torch.cat((x, y, z), dim=1).unsqueeze(0)\n",
    "\n",
    "def generate_donut(n, a = 1, b = 1, c = 1):\n",
    "    t1 = torch.linspace(0, 2*torch.pi - 1e-3, n)\n",
    "    t2 = torch.linspace(0, 2*torch.pi - 1e-3, n)\n",
    "    grid_t1, grid_t2 = torch.meshgrid((t1, t2), indexing='ij')\n",
    "    # t = torch.stack((grid_t1, grid_t2), dim=-1).reshape(-1, 2).to(device)\n",
    "    x = ((torch.sin(grid_t1) + 2) * torch.cos(grid_t2)).view(-1, 1)\n",
    "    y = ((torch.sin(grid_t1) + 2) *  torch.sin(grid_t2)).view(-1, 1)\n",
    "    z = 0.5*(torch.cos(grid_t1)).view(-1, 1)\n",
    "    return torch.cat((x, y, z), dim=1).unsqueeze(0)\n",
    "\n",
    "def generate_3D_ellipse(n, r1 = 1, r2 = 0.5):\n",
    "    t = torch.linspace(0, 2 * torch.pi, n+1)\n",
    "    x = (r1 * torch.cos(t)).view(-1, 1)[:-1]\n",
    "    y = (r2 * torch.sin(t)).view(-1, 1)[:-1]\n",
    "    z = (0 * torch.sin(t)).view(-1, 1)[:-1]\n",
    "    return torch.cat((x, y, z), dim=1).unsqueeze(0)\n",
    "\n",
    "\n",
    "def generate_ellipse(n, r1 = 1, r2 = 0.5):\n",
    "    t = torch.linspace(0, 2*torch.pi, n+1)\n",
    "    x = (r1 * torch.cos(t)).view(-1, 1)[:-1]\n",
    "    y = (r2 * torch.sin(t)).view(-1, 1)[:-1]\n",
    "    return torch.cat((x, y), dim=1).unsqueeze(0)\n",
    "\n",
    "def generate_data(n, sign = \"+\"):\n",
    "    line = generate_line(n, sign)\n",
    "    line2 = generate_line_small(n, sign = '-')\n",
    "    parabola = generate_parabola(n, sign)\n",
    "    parabola1 = generate_parabola(n, sign = '-')\n",
    "    circle = generate_circle(n)\n",
    "    circle1 = generate_circle(n, r=2)\n",
    "    e1 = generate_ellipse(n, r1 = 1.5, r2 = 3)\n",
    "    e2 = generate_ellipse(n, r1 = 4, r2 = 2)\n",
    "    curves =  generate_ellipse(n, r1 = 2.5, r2 = 2.5)\n",
    "    for i in range(10,30):\n",
    "        # for j in range(1,5):\n",
    "        e1 = generate_ellipse(n, r1 = i/4, r2 = i/4)\n",
    "        curves = torch.concat((curves, e1))\n",
    "    return curves\n",
    "\n",
    "def plot_data(data, mode = '3D'):\n",
    "    data = data.to(\"cpu\").detach().numpy()\n",
    "\n",
    "    if mode == '3D':\n",
    "        fig = plt.figure(figsize=(15, 5))  # Create a wide figure to accommodate three subplots\n",
    "\n",
    "        # First subplot\n",
    "        ax1 = fig.add_subplot(131, projection='3d')\n",
    "        ax1.set_xlabel('X')\n",
    "        ax1.set_ylabel('Y')\n",
    "        ax1.set_zlabel('Z')\n",
    "        ax1.view_init(elev=20, azim=30)  # Set the viewing angle\n",
    "        for i in range(data.shape[0]):\n",
    "            ax1.scatter(data[i, :, 0], data[i, :, 1], data[i, :, 2], alpha=1.0, s=0.5)\n",
    "        ax1.set_title('View 1')\n",
    "\n",
    "        # Second subplot\n",
    "        ax2 = fig.add_subplot(132, projection='3d')\n",
    "        ax2.set_xlabel('X')\n",
    "        ax2.set_ylabel('Y')\n",
    "        ax2.set_zlabel('Z')\n",
    "        ax2.view_init(elev=40, azim=60)  # Change the viewing angle\n",
    "        for i in range(data.shape[0]):\n",
    "            ax2.scatter(data[i, :, 0], data[i, :, 1], data[i, :, 2], alpha=1.0, s=0.5)\n",
    "        ax2.set_title('View 2')\n",
    "\n",
    "        # Third subplot\n",
    "        ax3 = fig.add_subplot(133, projection='3d')\n",
    "        ax3.set_xlabel('X')\n",
    "        ax3.set_ylabel('Y')\n",
    "        ax3.set_zlabel('Z')\n",
    "        ax3.view_init(elev=60, azim=90)  # Change the viewing angle again\n",
    "        for i in range(data.shape[0]):\n",
    "            ax3.scatter(data[i, :, 0], data[i, :, 1], data[i, :, 2], alpha=1.0, s=0.5)\n",
    "        ax3.set_title('View 3')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        for i in range(data.shape[0]):\n",
    "            plt.scatter(data[i, :, 0], data[i, :, 1], s=1.5)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "fmoDeYPFa35y"
   },
   "outputs": [],
   "source": [
    "class H_theta(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(H_theta, self).__init__()\n",
    "        # self.inp = nn.Linear(input_dim, 500)\n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.out = nn.Linear(500, output_dim)\n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.out = nn.Linear(500, output_dim)\n",
    "        self.model = \\\n",
    "        nn.Sequential(\n",
    "            nn.Linear(input_dim, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, 2000),\n",
    "            nn.ReLU(),\n",
    "            # nn.Linear(25, 25),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(2000, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, disp = False):\n",
    "        # inp = self.inp(x)\n",
    "        # relu = self.relu(inp)\n",
    "        # out = self.out(relu)\n",
    "        # if disp:\n",
    "        #     with torch.no_grad():\n",
    "        #         print(\"Layer 1: \\n\", torch.norm(inp, dim=2))\n",
    "        #         print(\"Layer 2 (Hiddin Layer): \\n\", torch.norm(relu, dim=2))\n",
    "        #         print(\"Layer Out: \\n\", torch.norm(out, dim = 2))\n",
    "        out = self.model(x)\n",
    "        return out\n",
    "    \n",
    "class H_theta_new(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(H_theta_new, self).__init__()\n",
    "        # self.inp = nn.Linear(input_dim, 500)\n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.out = nn.Linear(500, output_dim)\n",
    "        # self.relu = nn.ReLU()\n",
    "        # self.out = nn.Linear(500, output_dim)\n",
    "        self.model = \\\n",
    "        nn.Sequential(\n",
    "            nn.Linear(30, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, output_dim)\n",
    "        )\n",
    "\n",
    "        self.inject = \\\n",
    "        nn.Sequential(\n",
    "            nn.Linear(input_dim, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000, 2)\n",
    "        )\n",
    "        \n",
    "        self.model1 = \\\n",
    "        nn.Sequential(\n",
    "            nn.Linear(output_dim, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, 2000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2000, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, disp = False):\n",
    "        # print(\"input shape:\", x.shape) #100, 20, 2\n",
    "        sc = self.inject(x)\n",
    "        # print(\"injection shape\", sc.shape) #100, 20, 2\n",
    "        s = sc[:,:, 0].unsqueeze(-1)\n",
    "        s = torch.max(torch.tensor(0.), 1 + s)\n",
    "        c = sc[:,:, 1].unsqueeze(-1)\n",
    "        # print(\"s shape\", s.shape)\n",
    "        # print(\"c shape\", c.shape)\n",
    "        y = self.model(torch.ones((s.shape[0], s.shape[1], 30), device=device))\n",
    "        # print(\"y shape\", y.shape)\n",
    "        y = nn.LayerNorm(normalized_shape=2, device=device)(y)\n",
    "        x = (s*y + c).to(device)\n",
    "        x = self.model1(x).to(device)\n",
    "        # print(\"Out shape\", x.shape)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class H_theta_new(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, num_layers, num_layers_inject, num_neuron_inject, num_neurons):\n",
    "        super(H_theta_new, self).__init__()\n",
    "        assert num_layers % 2 == 0, \"Number of layers must be even for injection to occur after half.\"\n",
    "\n",
    "        half_layers = num_layers // 2\n",
    "\n",
    "        # First half of the model before injection\n",
    "        layers_before_inject = []\n",
    "        for i in range(half_layers):\n",
    "            if i == 0:\n",
    "                layers_before_inject.append(nn.Linear(30, num_neurons))\n",
    "            else:\n",
    "                layers_before_inject.append(nn.Linear(num_neurons, num_neurons))\n",
    "            layers_before_inject.append(nn.ReLU())\n",
    "        self.model_before_inject = nn.Sequential(*layers_before_inject)\n",
    "\n",
    "        # Injection submodel\n",
    "        inject_layers = []\n",
    "        for i in range(num_layers_inject):\n",
    "            if i == 0:\n",
    "                inject_layers.append(nn.Linear(input_dim, num_neuron_inject))\n",
    "            else:\n",
    "                inject_layers.append(nn.Linear(num_neuron_inject, num_neuron_inject))\n",
    "            inject_layers.append(nn.ReLU())\n",
    "        inject_layers.append(nn.Linear(num_neuron_inject, 2))\n",
    "        self.inject = nn.Sequential(*inject_layers)\n",
    "\n",
    "        # Second half of the model after injection\n",
    "        layers_after_inject = []\n",
    "        for i in range(half_layers):\n",
    "            layers_after_inject.append(nn.Linear(num_neurons, num_neurons))\n",
    "            layers_after_inject.append(nn.ReLU())\n",
    "        layers_after_inject.append(nn.Linear(num_neurons, output_dim))\n",
    "        self.model_after_inject = nn.Sequential(*layers_after_inject)\n",
    "\n",
    "        # Layer normalization\n",
    "        self.layer_norm = nn.LayerNorm(normalized_shape=num_neurons)\n",
    "\n",
    "    def forward(self, x, disp=False):\n",
    "        # First half\n",
    "        y = self.model_before_inject(torch.ones((x.shape[0], x.shape[1], 30), device=x.device))\n",
    "\n",
    "        # Injection\n",
    "        sc = self.inject(x)\n",
    "        s = torch.max(torch.tensor(0., device=x.device), 1 + sc[:, :, 0].unsqueeze(-1))\n",
    "        c = sc[:, :, 1].unsqueeze(-1)\n",
    "\n",
    "        # Apply normalization and combine\n",
    "        y = self.layer_norm(y)\n",
    "        x = (s * y + c).to(x.device)\n",
    "\n",
    "        # Second half\n",
    "        x = self.model_after_inject(x).to(x.device)\n",
    "\n",
    "        if disp:\n",
    "            print(f\"Input shape: {x.shape}, Injection shape: {sc.shape}, Output shape: {x.shape}\")\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def generate_NN_latent_functions(num_samples, xdim=1, zdim=2, bias=0):\n",
    "    class NN(nn.Module):\n",
    "        def __init__(self, input_dim, output_dim):\n",
    "            super(NN, self).__init__()\n",
    "            self.fc1 = nn.Linear(input_dim, 500)\n",
    "            #self.fc2 = nn.Linear(100, 100)\n",
    "            self.fc3 = nn.Linear(500, 500)\n",
    "            self.fc4 = nn.Linear(500, output_dim)\n",
    "\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        def forward(self, x):\n",
    "            with torch.no_grad():\n",
    "                x = torch.relu(self.fc1(x))\n",
    "                #x = torch.relu(self.fc2(x))\n",
    "                x = torch.relu(self.fc3(x))\n",
    "                x = self.fc4(x)\n",
    "            return x\n",
    "\n",
    "    #  weight initialization function\n",
    "    def weights_init_normal(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.normal_(m.weight, mean=0, std=1)\n",
    "            #nn.init.xavier_normal_(m.weight, gain = 0.5)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, val=bias)\n",
    "\n",
    "    #  neural networks\n",
    "    networks = []\n",
    "    for _ in range(num_samples):\n",
    "        net = NN(xdim, zdim)\n",
    "        net.apply(weights_init_normal)\n",
    "        networks.append(net)\n",
    "\n",
    "    return networks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "F_c-Vknda6qK"
   },
   "outputs": [],
   "source": [
    "def find_nns(Y, G, disp = False):\n",
    "    #Y: [1, 1024, 3]\n",
    "    #G: [20, 1024, 3]\n",
    "\n",
    "    distances = torch.sum(((Y - G) ** 2), dim = 2).mean(dim = 1)\n",
    "    min_, min_idx = torch.min(distances, dim=0)\n",
    "    return min_idx.item()\n",
    "\n",
    "def diffs(Y, G):\n",
    "    weighted_diffs = (G - Y)**2\n",
    "\n",
    "    diffs = torch.sum(weighted_diffs, dim=2)\n",
    "    return diffs\n",
    "\n",
    "def f_loss(Y, G):\n",
    "    diff = diffs(Y,G)\n",
    "    point_loss_mean = diff.mean(dim=1)\n",
    "    curve_loss_mean = point_loss_mean.mean(dim=0)\n",
    "    return curve_loss_mean\n",
    "\n",
    "\n",
    "\n",
    "def pos_encoder(x, L):\n",
    "\n",
    "    _, n = x.shape\n",
    "\n",
    "    encoding = []\n",
    "\n",
    "    for i in range(n):\n",
    "        for l in range(L):\n",
    "            encoding.append(torch.sin(1.1*(2**l) * torch.pi * x[:, i:i+1]))\n",
    "            encoding.append(torch.cos(1.1*(2**l) * torch.pi * x[:, i:i+1]))\n",
    "            # print('L:', l)\n",
    "            # print('x:',x[:, i:i+1])\n",
    "            # print('Trig_in: ', 1.1*(2**l) * x[:, i:i+1])\n",
    "            # print(\"Sin:\")\n",
    "            # print(torch.sin(1.1*(2**l) * torch.pi * x[:, i:i+1]))\n",
    "            # print(\"Cos:\")\n",
    "            # print(torch.cos(1.1*(2**l) * torch.pi * x[:, i:i+1]))\n",
    "            # print()\n",
    "    encoded_x = torch.cat(encoding, dim=-1)*5\n",
    "\n",
    "    return encoded_x\n",
    "\n",
    "\n",
    "x = torch.randn(2, 1)  # Example tensor with 10 points in 2D\n",
    "x = torch.Tensor([[-2],[2]])\n",
    "\n",
    "encoded_x = pos_encoder(x, L=3)\n",
    "#print(encoded_t)  # Should print torch.Size([10, 8])\n",
    "Zs = generate_NN_latent_functions(num_samples=3, xdim=6, zdim=4, bias=1)\n",
    "\n",
    "Z = (Zs[0](encoded_x))\n",
    "\n",
    "# print(\"Z shape: \", Z.shape)\n",
    "# print(\"encoded_x shape: \", encoded_x.shape)\n",
    "# print()\n",
    "# for i, model in enumerate(Zs):\n",
    "#     model = model\n",
    "#     #Zxs[i] = torch.cat((model(z_in), x), dim=1).to(device)\n",
    "#     Z = (model(encoded_x))\n",
    "#     print('Positional Encoding for x = -1:' )\n",
    "#     print(encoded_x[0])\n",
    "#     print(\"Output of Z_\"+str(i)+\" for x = -1:\")\n",
    "#     print(Z[0])\n",
    "#     print()\n",
    "#     print('Positional Encoding for x = 1:' )\n",
    "#     print(encoded_x[1])\n",
    "#     print(\"Output of Z_\"+str(i)+\" for x = 1:\")\n",
    "#     print(Z[1])\n",
    "#     print('-------------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# tensor1 = torch.randn(1, 1024, 3)\n",
    "# tensor2 = torch.randn(20, 1024, 3)\n",
    "# find_nns(tensor1, tensor2)\n",
    "\n",
    "\n",
    "# encoding.append(torch.sin(1.5*(2**l) * torch.pi * x[:, i:i+1]))\n",
    "# encoding.append(torch.cos(1.5*(2**l) * torch.pi * x[:, i:i+1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07uP81RFzXel",
    "outputId": "c1a0db47-26b9-4d4f-a126-cbdfb3862191"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "!del /Q /F \"plots/*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFaPRWIzNqzo"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "ozpG8FyXa-wK"
   },
   "outputs": [],
   "source": [
    "epochs = 10000\n",
    "staleness = 2\n",
    "num_Z_samples = 100\n",
    "lr = 0.0009\n",
    "num_points = 20\n",
    "xdim = 1\n",
    "zdim = 30         # lower and higher both not good, especially lower\n",
    "pos_enc_L = 6       # 7 does not converge, 5 and 8 worse than 6\n",
    "output_dim = 2\n",
    "plot_epoch = 500\n",
    "b1 = 0.85      # increasing and decreasing by 0.01 both worse\n",
    "b2 = 0.999\n",
    "gamma = 0.95\n",
    "step = 70\n",
    "z_scale = 100         # lower does not converge, higher is slower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uIiECz6FbhsL",
    "outputId": "769b4b83-042d-47de-be6d-799e1fb4be3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([21, 20, 2])\n"
     ]
    }
   ],
   "source": [
    "if xdim == 1:\n",
    "    x = torch.linspace(-0.05, 0.05, num_points).to(device).unsqueeze(1)\n",
    "else:\n",
    "    x1 = torch.linspace(1.0, 2, 40)\n",
    "    x2 = torch.linspace(1.0, 2, 40)\n",
    "    grid_x1, grid_x2 = torch.meshgrid((x1, x2), indexing='ij')\n",
    "    x = torch.stack((grid_x1, grid_x2), dim=-1).reshape(-1, 2).to(device)\n",
    "data = (generate_data(num_points)).to(device)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9gC9xPKSbm0a",
    "outputId": "cd1c8095-41a8-49a6-fa38-72c3f6ed503c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[100, 20, 2000]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     27\u001b[0m     Zxs[i] \u001b[38;5;241m=\u001b[39m (model(z_in)\u001b[38;5;241m/\u001b[39mz_scale)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 28\u001b[0m generated \u001b[38;5;241m=\u001b[39m \u001b[43mH_t\u001b[49m\u001b[43m(\u001b[49m\u001b[43mZxs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     30\u001b[0m imle_nns \u001b[38;5;241m=\u001b[39m [find_nns(d, generated) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m     31\u001b[0m imle_transformed_points \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty((data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], num_points, zdim))\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mc:\\Users\\rajsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rajsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[81], line 144\u001b[0m, in \u001b[0;36mH_theta_new.forward\u001b[1;34m(self, x, disp)\u001b[0m\n\u001b[0;32m    141\u001b[0m c \u001b[38;5;241m=\u001b[39m sc[:, :, \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# Apply normalization and combine\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m x \u001b[38;5;241m=\u001b[39m (s \u001b[38;5;241m*\u001b[39m y \u001b[38;5;241m+\u001b[39m c)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# Second half\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rajsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rajsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\rajsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:201\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rajsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:2546\u001b[0m, in \u001b[0;36mlayer_norm\u001b[1;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[0;32m   2542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[0;32m   2543\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m   2544\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[0;32m   2545\u001b[0m     )\n\u001b[1;32m-> 2546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given normalized_shape=[2], expected input with shape [*, 2], but got input of size[100, 20, 2000]"
     ]
    }
   ],
   "source": [
    "id += 1\n",
    "param_name = str(id)\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "# Initialize the model and optimizer\n",
    "H_t = H_theta_new(input_dim=zdim, output_dim=output_dim).to(device)\n",
    "#optimizer = optim.Adam(H_t.parameters(), lr=lr, eps=5e-1)\n",
    "optimizer = optim.AdamW(H_t.parameters(), lr=lr, betas=(b1, b2), eps = 1e-8)\n",
    "#optimizer = optim.SGD(H_t.parameters(), lr=lr, momentum=0.95)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, gamma=gamma, step_size= step)\n",
    "\n",
    "os.makedirs('notebook_plots/'+param_name, exist_ok=True)\n",
    "\n",
    "# Initialize lists to store gradient and parameter norms\n",
    "grad_norms = []\n",
    "param_norms = []\n",
    "losses = []\n",
    "Zxs = torch.empty((num_Z_samples, num_points, zdim)).to(device)\n",
    "z_in = pos_encoder(x, L=pos_enc_L)\n",
    "for e in tqdm(range(epochs)):\n",
    "    # Check if we need to update the stored model parameters\n",
    "    if e % staleness == 0:\n",
    "        Zs = generate_NN_latent_functions(num_samples=num_Z_samples, xdim=z_in.shape[1], zdim=zdim, bias=1)\n",
    "        for i, model in enumerate(Zs):\n",
    "            model = model.to(device)\n",
    "            Zxs[i] = (model(z_in)/z_scale).to(device)\n",
    "        generated = H_t(Zxs).to(device)\n",
    "\n",
    "        imle_nns = [find_nns(d, generated) for d in data]\n",
    "        imle_transformed_points = torch.empty((data.shape[0], num_points, zdim)).to(device)\n",
    "        # for i, index in enumerate(imle_nns):\n",
    "        #     imle_transformed_points[i] = Zxs[index]\n",
    "        perturbed_Zs = []\n",
    "        for i, idx in enumerate(imle_nns):\n",
    "            model = Zs[idx]\n",
    "            perturbed_model = copy.deepcopy(model)\n",
    "            with torch.no_grad():\n",
    "                for param in perturbed_model.parameters():\n",
    "                    param.add_(torch.randn_like(param) * 0.2)\n",
    "            perturbed_Zs.append(perturbed_model)\n",
    "            perturbed_model = perturbed_model.to(device)\n",
    "            imle_transformed_points[i] = (perturbed_model(z_in) / z_scale).to(device)\n",
    "\n",
    "    # Zero gradients, calculate loss, backpropagate, and update weights\n",
    "    optimizer.zero_grad()\n",
    "    outs = H_t(imle_transformed_points)\n",
    "    loss = f_loss(data, outs)\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    # Visualize generated points and save plots\n",
    "    #if e < 900 and e >= 800:\n",
    "    if e%plot_epoch == 0 or e == epochs - 1:\n",
    "        generated_disp = generated.to(device='cpu').detach().numpy()\n",
    "        outs_disp = outs.to(device='cpu').detach().numpy()\n",
    "        points_disp = data.to(device='cpu').detach().numpy()\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        for i in range(data.shape[0]):\n",
    "            line1 = plt.plot(outs_disp[i, :, 0], outs_disp[i, :, 1], marker='+')\n",
    "            color = line1[0].get_color()\n",
    "            plt.plot(points_disp[i, :, 0], points_disp[i, :, 1], marker='o', color=color)\n",
    "\n",
    "        #print(f'Epoch {str(e)}/{epochs}', str(loss.item()))\n",
    "\n",
    "        #plt.show()\n",
    "        #Save the figutes\n",
    "        \n",
    "        plt.title(f'Epoch: {e}')\n",
    "        plt.savefig(f\"notebook_plots/{param_name}/epoch_{e}.png\")\n",
    "        #Close plts\n",
    "        plt.close()\n",
    "        print(loss)\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.plot(losses, label='Loss')\n",
    "        plt.ylim(0, 15)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Loss Curve')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    # nn_utils.clip_grad_norm_(H_t.parameters(), max_norm=17.5)\n",
    "    # if e >= 75:\n",
    "    #     nn_utils.clip_grad_norm_(H_t.parameters(), max_norm=5)\n",
    "    # else:\n",
    "    #nn_utils.clip_grad_norm_(H_t.parameters(), max_norm=40)\n",
    "    # Calculate and store the norms of parameters and gradients\n",
    "    grad_sum = 0\n",
    "    param_sum = 0\n",
    "    for param in H_t.parameters():\n",
    "        param_sum += torch.norm(param)**2\n",
    "        grad_sum += torch.norm(param.grad)**2\n",
    "\n",
    "\n",
    "    # if e >= 570 and e <600:\n",
    "    #     print(\"68th Epoch Paramters\")\n",
    "    #     print(f\"Loss: {losses[67]}\")\n",
    "    #     print(f\"Diffs\", diffs(data, outs))\n",
    "    #     H_t(imle_transformed_points, disp = True)\n",
    "\n",
    "\n",
    "    # if e == 67:\n",
    "    #     print(\"68th Epoch Paramters\")\n",
    "    #     print(f\"Loss: {losses[67]}\")\n",
    "    #     print(f\"Diffs\", diffs(data, outs))\n",
    "    #     H_t(imle_transformed_points, disp = True)\n",
    "    #     for param in H_t.parameters():\n",
    "    #         print(param.grad.shape)\n",
    "    # if e == 68:\n",
    "    #     print(\"69th Epoch Paramters\")\n",
    "    #     print(f\"Loss: {losses[68]}\")\n",
    "    #     print(f\"Diffs\", diffs(data, outs))\n",
    "    #     H_t(imle_transformed_points, disp = True)\n",
    "    #     # for param in H_t.parameters():\n",
    "    #     #     print(param)\n",
    "    # if e == 69:\n",
    "    #     print(\"70th Epoch Paramters\")\n",
    "    #     print(f\"Loss: {losses[69]}\")\n",
    "    #     print(f\"Diffs\", diffs(data, outs))\n",
    "    #     H_t(imle_transformed_points, disp = True)\n",
    "\n",
    "\n",
    "    # if e == 74:\n",
    "    #     print(\"75th Epoch Paramters\")\n",
    "    #     print(f\"Loss: {losses[74]}\")\n",
    "    #     print(f\"Diffs\", diffs(data, outs))\n",
    "    #     H_t(imle_transformed_points, disp = True)\n",
    "    #     # for param in H_t.parameters():\n",
    "    #     #     print(param)\n",
    "\n",
    "\n",
    "    grad_norm = torch.sqrt(grad_sum).item()\n",
    "    param_norm = torch.sqrt(param_sum).item()\n",
    "    grad_norms.append(grad_norm)\n",
    "    param_norms.append(param_norm)\n",
    "\n",
    "    # print(\"Gradient Norm:\", grad_norm)\n",
    "    # print(\"Parameter Norm:\", param_norm)\n",
    "\n",
    "    optimizer.step()\n",
    "    #scheduler.step()\n",
    "\n",
    "# print(f\"25 Epochs: {losses[24]}\")\n",
    "# print(f\"50 Epochs: {losses[49]}\")\n",
    "# print(f\"100 Epochs: {losses[99]}\")\n",
    "# print(f\"150 Epochs: {losses[149]}\")\n",
    "# print(f\"200 Epochs: {losses[199]}\")\n",
    "\n",
    "# Plot the loss curve on a separate figure\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(losses, label='Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.savefig(f'notebook_plots/{param_name}/Loss Curve.png')\n",
    "#plt.xticks(np.arange(0, 75), 1)\n",
    "plt.show()\n",
    "\n",
    "# Plot gradient norms and parameter norms with dual y-axes\n",
    "\n",
    "#fig, ax1 = plt.subplots(figsize=(15, 5))\n",
    "# Plot gradient norms on the primary y-axis\n",
    "# ax1.plot(grad_norms, color='blue', label=\"Gradient Norms\")\n",
    "# ax1.set_xlabel('Epochs')\n",
    "# ax1.set_ylabel('Gradient Norms', color='blue')\n",
    "# ax1.tick_params(axis='y', labelcolor='blue')\n",
    "# ax1.set_xticks(np.arange(0, len(grad_norms), 25))\n",
    "# # Create a secondary y-axis for parameter norms\n",
    "# ax2 = ax1.twinx()\n",
    "# ax2.plot(param_norms, color='red', label=\"Parameter Norms\")\n",
    "# ax2.set_ylabel('Parameter Norms', color='red')\n",
    "# ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# # Title and layout adjustments\n",
    "# plt.title('Gradient and Parameter Norms over Epochs')\n",
    "\n",
    "# ax1.grid(True, which='both', axis='x', linestyle='--', linewidth=0.5)\n",
    "# fig.tight_layout()\n",
    "# plt.savefig(f'plots/{param_name}/ParamNorm vs GradNorm vs Epochs.png')\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# plt.plot(grad_norms, param_norms, marker='o')\n",
    "# plt.xlabel('Gradient Norms')\n",
    "# plt.ylabel('Parameter Norms')\n",
    "\n",
    "# plt.title('Parameter Norms vs. Gradient Norms')\n",
    "# plt.grid(True)\n",
    "# for i, (grad, param) in enumerate(zip(grad_norms, param_norms)):\n",
    "#     plt.text(grad, param, str(i), fontsize=8, ha='right', va='bottom')\n",
    "# plt.savefig(f'plots/{param_name}/ParamNorm vs GradNorm.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "s = s = 5\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.323881149291992\n"
     ]
    }
   ],
   "source": [
    "print(losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "hrl8_S8dXq1x"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'plots/7/Loss Curve.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[78], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss Curve\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[1;32m----> 7\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplots/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mparam_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/Loss Curve.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m#plt.xticks(np.arange(0, 75), 1)\u001b[39;00m\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\rajsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\pyplot.py:1023\u001b[0m, in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39msavefig)\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavefig\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1022\u001b[0m     fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[1;32m-> 1023\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1024\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\rajsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\figure.py:3378\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[1;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[0;32m   3374\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[0;32m   3375\u001b[0m         stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[0;32m   3376\u001b[0m             ax\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39m_cm_set(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m-> 3378\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rajsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2363\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[1;32m-> 2366\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2368\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2372\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2373\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32mc:\\Users\\rajsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   2228\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[0;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m   2231\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[1;32m-> 2232\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[0;32m   2235\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
      "File \u001b[1;32mc:\\Users\\rajsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    465\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rajsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\backends\\backend_agg.py:458\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[1;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    457\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 458\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rajsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\image.py:1689\u001b[0m, in \u001b[0;36mimsave\u001b[1;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[0;32m   1687\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1688\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[1;32m-> 1689\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rajsh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\Image.py:2435\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2433\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2434\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2435\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2438\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'plots/7/Loss Curve.png'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(losses, label='Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.legend()\n",
    "plt.savefig(f'plots/{param_name}/Loss Curve.png')\n",
    "#plt.xticks(np.arange(0, 75), 1)\n",
    "plt.show()\n",
    "\n",
    "# Plot gradient norms and parameter norms with dual y-axes\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(15, 5))\n",
    "# Plot gradient norms on the primary y-axis\n",
    "ax1.plot(grad_norms, color='blue', label=\"Gradient Norms\")\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Gradient Norms', color='blue')\n",
    "ax1.tick_params(axis='y', labelcolor='blue')\n",
    "ax1.set_xticks(np.arange(0, len(grad_norms), 25))\n",
    "# Create a secondary y-axis for parameter norms\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(param_norms, color='red', label=\"Parameter Norms\")\n",
    "ax2.set_ylabel('Parameter Norms', color='red')\n",
    "ax2.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Title and layout adjustments\n",
    "plt.title('Gradient and Parameter Norms over Epochs')\n",
    "\n",
    "ax1.grid(True, which='both', axis='x', linestyle='--', linewidth=0.5)\n",
    "fig.tight_layout()\n",
    "plt.savefig(f'plots/{param_name}/ParamNorm vs GradNorm vs Epochs.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.plot(grad_norms, param_norms, marker='o')\n",
    "plt.xlabel('Gradient Norms')\n",
    "plt.ylabel('Parameter Norms')\n",
    "\n",
    "plt.title('Parameter Norms vs. Gradient Norms')\n",
    "plt.grid(True)\n",
    "for i, (grad, param) in enumerate(zip(grad_norms, param_norms)):\n",
    "    plt.text(grad, param, str(i), fontsize=8, ha='right', va='bottom')\n",
    "plt.savefig(f'plots/{param_name}/ParamNorm vs GradNorm.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7MfknGGoSDh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
